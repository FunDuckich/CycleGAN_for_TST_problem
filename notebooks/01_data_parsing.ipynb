{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!pip install webdriver_manager"
      ],
      "metadata": {
        "id": "NLTRQBQ1BkVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPBNIB6DVwEc"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import time\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import zipfile\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Скачивание книг в формате .fb2"
      ],
      "metadata": {
        "id": "HfGjIQayXH1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pages_with_books(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    books_links = soup.find_all('a', class_='text-decoration-none')\n",
        "    books_urls = [link['href'] for link in books_links if ('href' in link.attrs and re.match(r\"^https://litlife\\.club/books/\\d+$\", link['href']))]\n",
        "    return books_urls"
      ],
      "metadata": {
        "id": "trhK1FG1Wrvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DwAgYq6MDrpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_fb2_file(page_url, download_dir):\n",
        "    options = webdriver.ChromeOptions()\n",
        "    prefs = {\"download.default_directory\": download_dir}\n",
        "    options.add_experimental_option(\"prefs\", prefs)\n",
        "    service = Service(ChromeDriverManager().install())\n",
        "    driver = webdriver.Chrome(service=service, options=options)\n",
        "    try:\n",
        "        driver.get(page_url)\n",
        "        wait = WebDriverWait(driver, 10)\n",
        "        download_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[contains(@href, '.fb2.zip')]\")))\n",
        "        download_button.click()\n",
        "        time.sleep(15)\n",
        "        print(f\"Файл должен быть загружен в: {download_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Произошла ошибка: {e}\")\n",
        "    finally:\n",
        "        driver.quit()"
      ],
      "metadata": {
        "id": "MWUqvJjCWx6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_dir = \"data\"\n",
        "count_of_pages = 20\n",
        "for x in range(count_of_pages):\n",
        "    main_page_url = f\"https://litlife.club/genres/56-klassicheskaya-proza?page={x}\"\n",
        "    books_url = get_pages_with_books(main_page_url)\n",
        "    for book in books_url:\n",
        "        download_fb2_file(book, download_dir)"
      ],
      "metadata": {
        "id": "D9S7RKrQW_pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Преоброзование файлов формата .fb2 в .txt"
      ],
      "metadata": {
        "id": "5mJ2OZGIWUt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_files = os.listdir(\"data\")\n",
        "for file_zip in all_files:\n",
        "    with zipfile.ZipFile(f\"data/{file_zip}\", 'r') as zip_ref:\n",
        "        for file in zip_ref.namelist():\n",
        "            if file.endswith(\".fb2\"):\n",
        "                try:\n",
        "                    fb2_file = zip_ref.open(file)\n",
        "                    fb2_content = fb2_file.read()\n",
        "                    text_content = ''\n",
        "                    soup = BeautifulSoup(fb2_content, 'lxml-xml')\n",
        "                    for para in soup.find_all(['p', 'section']):\n",
        "                        text_content += para.get_text(separator='\\n', strip=True) + '\\n'\n",
        "\n",
        "                    with open(f\"books_txt/{file}.txt\", 'w', encoding='utf-8') as txt_file:\n",
        "                        txt_file.write(text_content)\n",
        "                except FileNotFoundError:\n",
        "                    ..."
      ],
      "metadata": {
        "id": "wCzPmjVEWCEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}