{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e9b33e-1e8e-4f39-b24a-1fa809094860",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T14:49:07.899474Z",
          "iopub.status.busy": "2025-04-22T14:49:07.896561Z",
          "iopub.status.idle": "2025-04-22T14:49:13.983349Z",
          "shell.execute_reply": "2025-04-22T14:49:13.981848Z",
          "shell.execute_reply.started": "2025-04-22T14:49:07.899348Z"
        },
        "tags": [],
        "id": "d7e9b33e-1e8e-4f39-b24a-1fa809094860"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, get_linear_schedule_with_warmup, BertModel\n",
        "import time\n",
        "import torch.profiler\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bf523b8-0c45-42b2-a71f-871cf9f308da",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T14:49:13.991534Z",
          "iopub.status.busy": "2025-04-22T14:49:13.987499Z",
          "iopub.status.idle": "2025-04-22T14:49:17.339995Z",
          "shell.execute_reply": "2025-04-22T14:49:17.337479Z",
          "shell.execute_reply.started": "2025-04-22T14:49:13.991477Z"
        },
        "tags": [],
        "id": "7bf523b8-0c45-42b2-a71f-871cf9f308da"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используем устройство: {device}\")\n",
        "\n",
        "TOKENIZER_MODEL = \"DeepPavlov/rubert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_MODEL, force_download=True)\n",
        "\n",
        "EMBED_DIM = 768\n",
        "VOCAB_SIZE = tokenizer.vocab_size  # ~119,547\n",
        "MAX_SEQ_LEN = 96\n",
        "BATCH_SIZE = 4032\n",
        "NUM_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-4\n",
        "WARMUP_STEPS = 1000\n",
        "PATIENCE = 5\n",
        "MIN_DELTA = 0.0005\n",
        "NUM_LAYERS = 3\n",
        "NUM_HEADS = 8\n",
        "FF_DIM = 1024\n",
        "DROPOUT = 0.1\n",
        "NUM_WORKERS = 0\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BEAM_WIDTH = 5\n",
        "TEMPERATURE = 1.0\n",
        "ADAPTIVE_CUTOFFS = [510, 30269, 60028, 89787]\n",
        "ADAPTIVE_DIV_VALUE = 4\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "teacher_forcing_ratios = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7131f60c-4f0e-4e04-be86-a1e120000e43",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T14:49:17.346846Z",
          "iopub.status.busy": "2025-04-22T14:49:17.343847Z",
          "iopub.status.idle": "2025-04-22T14:49:17.374663Z",
          "shell.execute_reply": "2025-04-22T14:49:17.373600Z",
          "shell.execute_reply.started": "2025-04-22T14:49:17.346783Z"
        },
        "tags": [],
        "id": "7131f60c-4f0e-4e04-be86-a1e120000e43"
      },
      "outputs": [],
      "source": [
        "def clear_gpu_memory():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "def preprocess_texts(texts=None, tokenizer=tokenizer, max_seq_len=MAX_SEQ_LEN, output_file=\"tokenized_texts.npy\"):\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\"Загружаем готовые токены из {output_file}\")\n",
        "        return np.load(output_file, allow_pickle=True)\n",
        "    if texts is None:\n",
        "        raise ValueError(\"Файл tokenized_texts.npy не найден, и тексты не предоставлены!\")\n",
        "    print(\"Токенизация текстов...\")\n",
        "    tokenized = []\n",
        "    for text in tqdm(texts, desc=\"Токенизация\"):\n",
        "        tokens = tokenizer.encode(text, max_length=max_seq_len - 1, truncation=True, padding='max_length')\n",
        "        tokens = tokens + [tokenizer.sep_token_id]\n",
        "        if len(tokens) < max_seq_len:\n",
        "            tokens += [tokenizer.pad_token_id] * (max_seq_len - len(tokens))\n",
        "        tokenized.append(tokens)\n",
        "    tokenized = np.array(tokenized, dtype=np.int64)\n",
        "    np.save(output_file, tokenized)\n",
        "    print(f\"Токены сохранены в {output_file}\")\n",
        "    return tokenized\n",
        "\n",
        "def get_teacher_forcing_ratio(epoch):\n",
        "    if epoch < 80:\n",
        "        return 1.0 - (epoch / 80)\n",
        "    else:\n",
        "        return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08a8d2a-5796-4ec8-a070-4db5fe3f3e9f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T16:56:25.057644Z",
          "iopub.status.busy": "2025-04-22T16:56:25.054414Z",
          "iopub.status.idle": "2025-04-22T16:56:25.117065Z",
          "shell.execute_reply": "2025-04-22T16:56:25.115196Z",
          "shell.execute_reply.started": "2025-04-22T16:56:25.057521Z"
        },
        "tags": [],
        "id": "e08a8d2a-5796-4ec8-a070-4db5fe3f3e9f"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, embed_dim=768, vocab_size=119547, num_layers=3,\n",
        "                 num_heads=8, ff_dim=1024, dropout=0.1, max_seq_len=96, freq_file=\"token_frequencies.npy\", beta=0.5):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        self.input_norm = nn.LayerNorm(embed_dim)\n",
        "        self.input_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_seq_len, embed_dim)\n",
        "\n",
        "        self.register_buffer(\"position_ids\", torch.arange(max_seq_len).unsqueeze(0), persistent=False)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim,\n",
        "            dropout=dropout, batch_first=True, activation='gelu'\n",
        "        )\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.output_layer = nn.AdaptiveLogSoftmaxWithLoss(\n",
        "            in_features=embed_dim,\n",
        "            n_classes=vocab_size,\n",
        "            cutoffs=[510, 30269, 60028, 89787],\n",
        "            div_value=4,\n",
        "            head_bias=True\n",
        "        )\n",
        "\n",
        "        self.mask_cache = {}\n",
        "\n",
        "        if os.path.exists(freq_file):\n",
        "            freqs = np.load(freq_file)\n",
        "            freq_tensor = torch.from_numpy(freqs).float()\n",
        "            bias = beta * torch.log(freq_tensor + 1.0)\n",
        "            self.register_buffer('freq_bias', bias)\n",
        "        else:\n",
        "            print(f\"Файл {freq_file} не найден, freq_bias не будет использоваться.\")\n",
        "\n",
        "    def _get_tgt_mask(self, seq_len, device):\n",
        "        if seq_len not in self.mask_cache:\n",
        "            mask = torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1)\n",
        "            mask = mask.masked_fill(mask == 1, float('-inf'))\n",
        "            self.mask_cache[seq_len] = mask\n",
        "        return self.mask_cache[seq_len]\n",
        "\n",
        "    def forward(self, src_embed, tgt, teacher_forcing_ratio=1.0):\n",
        "        batch_size, seq_len = tgt.size()\n",
        "        device = tgt.device\n",
        "\n",
        "        src_embed = self.input_norm(src_embed)\n",
        "        memory = self.input_proj(src_embed).unsqueeze(1)\n",
        "\n",
        "        positions = self.position_ids[:, :seq_len].expand(batch_size, seq_len)\n",
        "        tgt_mask = self._get_tgt_mask(seq_len, device)\n",
        "\n",
        "        if teacher_forcing_ratio >= 1.0:\n",
        "            input_ids = tgt\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                decoder_input_ids = torch.zeros_like(tgt)\n",
        "                decoder_input_ids[:, 0] = tokenizer.cls_token_id\n",
        "\n",
        "                embedded = self.token_embedding(decoder_input_ids) + self.pos_embedding(positions)\n",
        "                logits = self.decoder(self.dropout(embedded), memory, tgt_mask=tgt_mask)\n",
        "\n",
        "                predicted_ids = self.output_layer.predict(logits.reshape(-1, self.embed_dim)).reshape(batch_size, seq_len)\n",
        "\n",
        "            use_teacher = torch.rand(batch_size, seq_len - 1, device=device) < teacher_forcing_ratio\n",
        "            input_ids = tgt.clone()\n",
        "            input_ids[:, 1:] = torch.where(use_teacher, tgt[:, 1:], predicted_ids[:, 1:])\n",
        "\n",
        "        decoder_input = self.token_embedding(input_ids) + self.pos_embedding(positions)\n",
        "        decoder_input = self.dropout(decoder_input)\n",
        "\n",
        "        output = self.decoder(decoder_input, memory, tgt_mask=tgt_mask)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate(self, src_embed, max_len=96, start_token_id=None, beam_width=5, temperature=1.0, alpha=0.7, top_k=50, top_p=0.9, min_length=10):\n",
        "        batch_size = src_embed.size(0)\n",
        "        device = src_embed.device\n",
        "        start_token_id = start_token_id or tokenizer.cls_token_id\n",
        "        sep_token_id = tokenizer.sep_token_id\n",
        "\n",
        "        src_embed = self.input_norm(src_embed).unsqueeze(1)\n",
        "        memory = self.input_proj(src_embed)\n",
        "\n",
        "        beams = [(torch.full((1, 1), start_token_id, device=device), 0.0)]\n",
        "        completed_beams = []\n",
        "\n",
        "        for step in range(max_len - 1):\n",
        "            all_candidates = []\n",
        "            for seq, score in beams:\n",
        "                if seq[0, -1] == sep_token_id and step >= min_length:\n",
        "                    completed_beams.append((seq, score))\n",
        "                    continue\n",
        "\n",
        "                seq_len = seq.size(1)\n",
        "                positions = self.position_ids[:, :seq_len].expand(1, seq_len)\n",
        "                tgt_embed = self.token_embedding(seq) + self.pos_embedding(positions)\n",
        "                mask = self._get_tgt_mask(seq_len, device)\n",
        "\n",
        "                output = self.decoder(tgt_embed, memory, tgt_mask=mask)\n",
        "                hidden = output[:, -1, :]\n",
        "\n",
        "                log_probs = self.output_layer.log_prob(hidden)\n",
        "                log_probs = log_probs / temperature\n",
        "                probs = torch.exp(log_probs)\n",
        "\n",
        "                if hasattr(self, 'freq_bias'):\n",
        "                    log_probs = log_probs - self.freq_bias\n",
        "                    probs = torch.exp(log_probs)\n",
        "\n",
        "                sorted_probs, sorted_indices = torch.sort(probs, descending=True, dim=-1)\n",
        "                cumsum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "                selected_mask = cumsum_probs <= top_p\n",
        "                selected_mask[:, 0] = True\n",
        "                num_selected = selected_mask.sum(dim=-1).max()\n",
        "                top_p_probs = sorted_probs[:, :num_selected]\n",
        "                top_p_indices = sorted_indices[:, :num_selected]\n",
        "\n",
        "                top_k = min(top_k, num_selected.item())\n",
        "                top_k_probs, top_k_indices = torch.topk(top_p_probs, top_k, dim=-1)\n",
        "                top_k_indices = top_p_indices.gather(-1, top_k_indices)\n",
        "\n",
        "                top_beam_probs, top_beam_indices = torch.topk(top_k_probs, beam_width, dim=-1)\n",
        "                top_beam_indices = top_k_indices.gather(-1, top_beam_indices)\n",
        "\n",
        "                for i in range(beam_width):\n",
        "                    next_token = top_beam_indices[:, i].unsqueeze(0)\n",
        "                    log_prob = torch.log(top_beam_probs[:, i] + 1e-10)\n",
        "                    new_seq = torch.cat([seq, next_token], dim=1)\n",
        "                    new_score = score + log_prob.item()\n",
        "                    all_candidates.append((new_seq, new_score))\n",
        "\n",
        "            beams = sorted(all_candidates, key=lambda x: x[1] / ((5 + len(x[0][0])) ** alpha / (6 ** alpha)), reverse=True)[:beam_width]\n",
        "            if not beams:\n",
        "                break\n",
        "\n",
        "        beams.extend(completed_beams)\n",
        "        if not beams:\n",
        "            return torch.full((batch_size, 1), start_token_id, device=device)\n",
        "\n",
        "        best_seq = max(beams, key=lambda x: x[1])[0]\n",
        "        return best_seq.expand(batch_size, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faebbee8-a553-45fe-996a-18070fd40ce2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-15T17:44:59.624368Z",
          "iopub.status.busy": "2025-04-15T17:44:59.624030Z",
          "iopub.status.idle": "2025-04-15T17:44:59.972395Z",
          "shell.execute_reply": "2025-04-15T17:44:59.971621Z",
          "shell.execute_reply.started": "2025-04-15T17:44:59.624348Z"
        },
        "tags": [],
        "id": "faebbee8-a553-45fe-996a-18070fd40ce2",
        "outputId": "a3d0e18d-9778-4e07-eef2-3409944927bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Загружаем готовые токены из tokenized_texts.npy\n"
          ]
        }
      ],
      "source": [
        "tokenized_texts = preprocess_texts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ba3d98-b01a-46a6-a7d6-9e49c598cce7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-13T09:30:40.606583Z",
          "iopub.status.busy": "2025-04-13T09:30:40.605404Z",
          "iopub.status.idle": "2025-04-13T09:32:11.177705Z",
          "shell.execute_reply": "2025-04-13T09:32:11.176757Z",
          "shell.execute_reply.started": "2025-04-13T09:30:40.606546Z"
        },
        "id": "39ba3d98-b01a-46a6-a7d6-9e49c598cce7"
      },
      "outputs": [],
      "source": [
        "counts = {}\n",
        "\n",
        "for text in tokenized_texts:\n",
        "    for token_id in text:\n",
        "        if token_id in counts:\n",
        "            counts[token_id] += 1\n",
        "        else:\n",
        "            counts[token_id] = 1\n",
        "\n",
        "frequencies = np.zeros(VOCAB_SIZE, dtype=np.int32)\n",
        "\n",
        "for token_id, freq in counts.items():\n",
        "    frequencies[token_id] = freq\n",
        "\n",
        "np.save(\"token_frequencies.npy\", frequencies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f34c07-7ba4-484e-835f-aad75e35fc33",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T15:58:26.079540Z",
          "iopub.status.busy": "2025-04-20T15:58:26.076693Z",
          "iopub.status.idle": "2025-04-20T15:58:26.139804Z",
          "shell.execute_reply": "2025-04-20T15:58:26.137255Z",
          "shell.execute_reply.started": "2025-04-20T15:58:26.079399Z"
        },
        "id": "73f34c07-7ba4-484e-835f-aad75e35fc33"
      },
      "outputs": [],
      "source": [
        "freqs = np.load(\"token_frequencies.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa13a0f-868b-49d8-b661-a2b71215aa62",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T16:08:29.511268Z",
          "iopub.status.busy": "2025-04-20T16:08:29.507828Z",
          "iopub.status.idle": "2025-04-20T16:08:29.540621Z",
          "shell.execute_reply": "2025-04-20T16:08:29.538508Z",
          "shell.execute_reply.started": "2025-04-20T16:08:29.511126Z"
        },
        "tags": [],
        "id": "2aa13a0f-868b-49d8-b661-a2b71215aa62",
        "outputId": "a14935d8-35f0-45bc-ec5b-44e185b0ba0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freqs[129:].argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61629a0-7061-4e8f-ae14-9b3ee40b58ab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T16:08:35.501324Z",
          "iopub.status.busy": "2025-04-20T16:08:35.497965Z",
          "iopub.status.idle": "2025-04-20T16:08:35.557261Z",
          "shell.execute_reply": "2025-04-20T16:08:35.554828Z",
          "shell.execute_reply.started": "2025-04-20T16:08:35.501170Z"
        },
        "tags": [],
        "id": "c61629a0-7061-4e8f-ae14-9b3ee40b58ab",
        "outputId": "f3be3a5f-c983-4419-b313-af55d6dd38c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode([132])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d162ad6c-0ac8-4a1a-b3fc-d1c2ced98ff4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-15T18:10:13.823472Z",
          "iopub.status.busy": "2025-04-15T18:10:13.822944Z",
          "iopub.status.idle": "2025-04-15T18:10:16.613617Z",
          "shell.execute_reply": "2025-04-15T18:10:16.612618Z",
          "shell.execute_reply.started": "2025-04-15T18:10:13.823452Z"
        },
        "tags": [],
        "id": "d162ad6c-0ac8-4a1a-b3fc-d1c2ced98ff4",
        "outputId": "75ea0758-74a5-4e4e-f70a-6844cb1a5d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Загружаем готовые токены из tokenized_texts.npy\n"
          ]
        }
      ],
      "source": [
        "lit_embeddings = np.load(\"lit_embeddings.npy\")\n",
        "tg_embeddings = np.load(\"conv_embeddings.npy\")\n",
        "embeddings = np.concatenate([lit_embeddings, tg_embeddings], axis=0)\n",
        "tokenized_texts = preprocess_texts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b0bbe5-e934-4dcb-825a-747dd78e7d7a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-15T18:10:16.615208Z",
          "iopub.status.busy": "2025-04-15T18:10:16.614686Z",
          "iopub.status.idle": "2025-04-15T18:10:16.627690Z",
          "shell.execute_reply": "2025-04-15T18:10:16.626980Z",
          "shell.execute_reply.started": "2025-04-15T18:10:16.615186Z"
        },
        "tags": [],
        "id": "16b0bbe5-e934-4dcb-825a-747dd78e7d7a",
        "outputId": "12630eec-5af2-4643-b3e6-0f3610f240da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "68500"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TOTAL_STEPS = (len(embeddings) // BATCH_SIZE) * NUM_EPOCHS\n",
        "TOTAL_STEPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2042ce3-3895-41e7-9eb7-b8bf48399081",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-15T18:10:16.628903Z",
          "iopub.status.busy": "2025-04-15T18:10:16.628540Z",
          "iopub.status.idle": "2025-04-15T18:10:16.640090Z",
          "shell.execute_reply": "2025-04-15T18:10:16.639372Z",
          "shell.execute_reply.started": "2025-04-15T18:10:16.628883Z"
        },
        "tags": [],
        "id": "b2042ce3-3895-41e7-9eb7-b8bf48399081"
      },
      "outputs": [],
      "source": [
        "class EmbeddingToTokenDataset(Dataset):\n",
        "    def __init__(self, embeddings, tokenized_texts):\n",
        "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
        "        self.tokenized_texts = torch.tensor(tokenized_texts, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.embeddings[idx], self.tokenized_texts[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a5507f-8be4-40b7-a1ae-81dda0dcd2ca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-15T18:10:16.641101Z",
          "iopub.status.busy": "2025-04-15T18:10:16.640793Z",
          "iopub.status.idle": "2025-04-15T18:10:17.250218Z",
          "shell.execute_reply": "2025-04-15T18:10:17.249516Z",
          "shell.execute_reply.started": "2025-04-15T18:10:16.641082Z"
        },
        "tags": [],
        "id": "00a5507f-8be4-40b7-a1ae-81dda0dcd2ca"
      },
      "outputs": [],
      "source": [
        "dataset = EmbeddingToTokenDataset(embeddings, tokenized_texts)\n",
        "dataset_size = len(dataset)\n",
        "val_size = int(VALIDATION_SPLIT * dataset_size)\n",
        "train_size = dataset_size - val_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dbeec5c-73b5-488d-bcd2-ef7c7745099f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-15T18:10:17.251431Z",
          "iopub.status.busy": "2025-04-15T18:10:17.251020Z",
          "iopub.status.idle": "2025-04-15T18:10:17.262037Z",
          "shell.execute_reply": "2025-04-15T18:10:17.261436Z",
          "shell.execute_reply.started": "2025-04-15T18:10:17.251410Z"
        },
        "tags": [],
        "id": "5dbeec5c-73b5-488d-bcd2-ef7c7745099f"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=NUM_WORKERS)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a763ec2e-984c-4462-ae3e-35c94921f06e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-15T18:10:17.319114Z",
          "iopub.status.busy": "2025-04-15T18:10:17.318784Z",
          "iopub.status.idle": "2025-04-15T18:10:18.571403Z",
          "shell.execute_reply": "2025-04-15T18:10:18.570606Z",
          "shell.execute_reply.started": "2025-04-15T18:10:17.319093Z"
        },
        "tags": [],
        "id": "a763ec2e-984c-4462-ae3e-35c94921f06e"
      },
      "outputs": [],
      "source": [
        "model = TransformerDecoder().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=TOTAL_STEPS)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62599e7a-1c82-4bef-b347-84743f948f6a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-15T18:10:18.573007Z",
          "iopub.status.busy": "2025-04-15T18:10:18.572680Z",
          "iopub.status.idle": "2025-04-15T18:10:18.593929Z",
          "shell.execute_reply": "2025-04-15T18:10:18.593252Z",
          "shell.execute_reply.started": "2025-04-15T18:10:18.572986Z"
        },
        "tags": [],
        "id": "62599e7a-1c82-4bef-b347-84743f948f6a"
      },
      "outputs": [],
      "source": [
        "best_val_loss = float('inf')\n",
        "patience_counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9faf5bec-adb3-4edd-a5ca-e08b2570e50e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-16T04:44:11.265742Z",
          "iopub.status.busy": "2025-04-16T04:44:11.264256Z",
          "iopub.status.idle": "2025-04-16T04:44:11.302966Z",
          "shell.execute_reply": "2025-04-16T04:44:11.301306Z",
          "shell.execute_reply.started": "2025-04-16T04:44:11.265694Z"
        },
        "tags": [],
        "id": "9faf5bec-adb3-4edd-a5ca-e08b2570e50e"
      },
      "outputs": [],
      "source": [
        "train_times = []\n",
        "val_times = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    teacher_forcing_ratio = get_teacher_forcing_ratio(epoch)\n",
        "    teacher_forcing_ratios.append(teacher_forcing_ratio)\n",
        "    print(f\"Эпоха {epoch+1}, Teacher Forcing Ratio: {teacher_forcing_ratio:.3f}\")\n",
        "\n",
        "    model.train()\n",
        "    train_loss_total = 0\n",
        "    train_start_time = time.time()\n",
        "    for i, (src_embed, tgt) in enumerate(tqdm(train_dataloader, desc=f\"Тренировка, Эпоха {epoch+1}/{NUM_EPOCHS}\")):\n",
        "        src_embed = src_embed.to(device, non_blocking=True)\n",
        "        tgt = tgt.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(dtype=torch.float16):\n",
        "            output = model(src_embed, tgt[:, :-1], teacher_forcing_ratio)\n",
        "            tgt_shifted = tgt[:, 1:].reshape(-1)\n",
        "            loss_output = model.output_layer(output.reshape(-1, EMBED_DIM), tgt_shifted)\n",
        "            loss = loss_output.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scheduler.step()\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss_total += loss.item()\n",
        "\n",
        "        if i == 0:\n",
        "            print(f\"Размер src_embed: {src_embed.shape}\")\n",
        "            print(f\"Размер tgt: {tgt.shape}\")\n",
        "            print(f\"Память GPU после первого батча: {torch.cuda.memory_allocated()/1024**3:.2f} ГБ\")\n",
        "\n",
        "    train_end_time = time.time()\n",
        "    train_times.append(train_end_time - train_start_time)\n",
        "    avg_train_loss = train_loss_total / len(train_dataloader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(f\"Эпоха {epoch+1}/{NUM_EPOCHS}, Тренировочный лосс: {avg_train_loss:.4f}, Время тренировки: {train_times[-1]:.2f} секунд\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss_total = 0\n",
        "    val_start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for src_embed, tgt in tqdm(val_dataloader, desc=f\"Валидация, Эпоха {epoch+1}/{NUM_EPOCHS}\"):\n",
        "            src_embed = src_embed.to(device, non_blocking=True)\n",
        "            tgt = tgt.to(device, non_blocking=True)\n",
        "            with autocast(dtype=torch.float16):\n",
        "                output = model(src_embed, tgt[:, :-1], teacher_forcing_ratio=0.0)\n",
        "                tgt_shifted = tgt[:, 1:].reshape(-1)\n",
        "                loss_output = model.output_layer(output.reshape(-1, EMBED_DIM), tgt_shifted)\n",
        "                loss = loss_output.loss\n",
        "\n",
        "            val_loss_total += loss.item()\n",
        "\n",
        "    val_end_time = time.time()\n",
        "    val_times.append(val_end_time - val_start_time)\n",
        "    avg_val_loss = val_loss_total / len(val_dataloader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(f\"Эпоха {epoch+1}/{NUM_EPOCHS}, Валидационный лосс: {avg_val_loss:.4f}, Время валидации: {val_times[-1]:.2f} секунд\")\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "    ax1.plot(train_losses, label='Train Loss', color='blue')\n",
        "    ax1.plot(val_losses, label='Validation Loss', color='orange')\n",
        "    ax1.set_xlabel('Эпоха')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend(loc='upper left')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(teacher_forcing_ratios, label='Teacher Forcing Ratio', color='green', linestyle='--')\n",
        "    ax2.set_ylabel('Teacher Forcing Ratio')\n",
        "    ax2.legend(loc='upper right')\n",
        "\n",
        "    plt.title('График обучения и Teacher Forcing Ratio')\n",
        "    plt.savefig(\"loss.png\")\n",
        "    plt.close()\n",
        "\n",
        "    if avg_val_loss < best_val_loss - MIN_DELTA:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model, \"decoder_model.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Ранний останов\")\n",
        "            break\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "    print(f\"Общее время эпохи {epoch+1}: {epoch_end_time - epoch_start_time:.2f} секунд\")\n",
        "    clear_gpu_memory()\n",
        "\n",
        "print(\"Финальная модель сохранена\")\n",
        "clear_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afffdb30-1627-4fa5-817f-4317681a9338",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T14:59:08.367535Z",
          "iopub.status.busy": "2025-04-22T14:59:08.364616Z",
          "iopub.status.idle": "2025-04-22T15:00:11.407794Z",
          "shell.execute_reply": "2025-04-22T15:00:11.405790Z",
          "shell.execute_reply.started": "2025-04-22T14:59:08.367417Z"
        },
        "tags": [],
        "id": "afffdb30-1627-4fa5-817f-4317681a9338"
      },
      "outputs": [],
      "source": [
        "bert_model = BertModel.from_pretrained(\"DeepPavlov/rubert-base-cased\", force_download=True).to(device)\n",
        "bert_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2428a32-7fb9-45c3-8ea6-32d2cc632f96",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T16:56:43.469038Z",
          "iopub.status.busy": "2025-04-22T16:56:43.465503Z",
          "iopub.status.idle": "2025-04-22T16:56:44.913736Z",
          "shell.execute_reply": "2025-04-22T16:56:44.912242Z",
          "shell.execute_reply.started": "2025-04-22T16:56:43.468872Z"
        },
        "tags": [],
        "id": "f2428a32-7fb9-45c3-8ea6-32d2cc632f96",
        "outputId": "c1abbc09-abaa-42f9-cd2d-26409cd5333c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TransformerDecoder(\n",
              "  (input_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (input_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (token_embedding): Embedding(119547, 768)\n",
              "  (pos_embedding): Embedding(96, 768)\n",
              "  (decoder): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
              "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (output_layer): AdaptiveLogSoftmaxWithLoss(\n",
              "    (head): Linear(in_features=768, out_features=514, bias=True)\n",
              "    (tail): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=192, bias=False)\n",
              "        (1): Linear(in_features=192, out_features=29759, bias=False)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=48, bias=False)\n",
              "        (1): Linear(in_features=48, out_features=29759, bias=False)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=12, bias=False)\n",
              "        (1): Linear(in_features=12, out_features=29759, bias=False)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3, bias=False)\n",
              "        (1): Linear(in_features=3, out_features=29760, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TransformerDecoder(beta=2.0).to(device)\n",
        "model.load_state_dict(torch.load(\"decoder_model.pth\", map_location=device).state_dict(), strict=False)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef16bb6d-4d87-4841-85b1-aa53cc7373d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T16:56:55.168372Z",
          "iopub.status.busy": "2025-04-22T16:56:55.165496Z",
          "iopub.status.idle": "2025-04-22T16:56:55.201915Z",
          "shell.execute_reply": "2025-04-22T16:56:55.199672Z",
          "shell.execute_reply.started": "2025-04-22T16:56:55.168249Z"
        },
        "tags": [],
        "id": "ef16bb6d-4d87-4841-85b1-aa53cc7373d3",
        "outputId": "451c3477-db4f-4067-ff13-a1fad85078d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Частота токена 'У' (ID 815): 37377\n",
            "Частота токена 'меня' (ID 14198): 97863\n",
            "Частота токена 'Правоохранительные' (ID 50863): 0\n",
            "Частота токена '##лашение' (ID 31213): 0\n",
            "Частота токена '[unused66]' (ID 66): 0\n",
            "Частота токена '[unused41]' (ID 41): 0\n"
          ]
        }
      ],
      "source": [
        "freqs = np.load(\"token_frequencies.npy\")\n",
        "print(f\"Частота токена 'У' (ID 815): {freqs[815]}\")\n",
        "print(f\"Частота токена 'меня' (ID 14198): {freqs[14198]}\")\n",
        "print(f\"Частота токена 'Правоохранительные' (ID 50863): {freqs[50863]}\")\n",
        "print(f\"Частота токена '##лашение' (ID 31213): {freqs[31213]}\")\n",
        "print(f\"Частота токена '[unused66]' (ID 66): {freqs[66]}\")\n",
        "print(f\"Частота токена '[unused41]' (ID 41): {freqs[41]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21afb709-e29f-4a92-9b26-563c9aa88a09",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T16:57:12.456557Z",
          "iopub.status.busy": "2025-04-22T16:57:12.453719Z",
          "iopub.status.idle": "2025-04-22T16:58:19.677038Z",
          "shell.execute_reply": "2025-04-22T16:58:19.675222Z",
          "shell.execute_reply.started": "2025-04-22T16:57:12.456434Z"
        },
        "tags": [],
        "id": "21afb709-e29f-4a92-9b26-563c9aa88a09"
      },
      "outputs": [],
      "source": [
        "text = \"какие сладкие булочки!\"\n",
        "tokens = tokenizer.encode(text, max_length=MAX_SEQ_LEN - 1, truncation=True, padding='max_length')\n",
        "tokens = tokens + [tokenizer.sep_token_id]\n",
        "input_ids = torch.tensor([tokens]).to(device)\n",
        "attention_mask = (input_ids != tokenizer.pad_token_id).long().to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "    generated = model.generate(cls_embedding, max_len=MAX_SEQ_LEN, beam_width=20, temperature=0.7, top_k=50, top_p=0.7, alpha=0.8, min_length=10)\n",
        "    res = tokenizer.decode(generated[0].tolist(), skip_special_tokens=True)\n",
        "    print(\"Generated token IDs:\", generated[0].tolist())\n",
        "    print(\"Corresponding tokens:\", tokenizer.convert_ids_to_tokens(generated[0].tolist()))\n",
        "    print(\"Decoded output:\", res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185ec665-c058-4387-9f0e-8ba9ea05eca0",
      "metadata": {
        "id": "185ec665-c058-4387-9f0e-8ba9ea05eca0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DataSphere Kernel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}